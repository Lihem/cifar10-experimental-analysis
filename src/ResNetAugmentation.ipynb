{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Weights and Biases related imports\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (50000, 32, 32, 3)\n",
      "Train Labels Shape: (50000, 10)\n",
      "Test Data Shape: (10000, 32, 32, 3)\n",
      "Test Labels Shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_cifar10_batch(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='bytes')\n",
    "    return batch\n",
    "\n",
    "def load_cifar10_data(folder_path):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        batch_file = f\"{folder_path}/data_batch_{i}\"\n",
    "        batch = load_cifar10_batch(batch_file)\n",
    "        train_data.append(batch[b'data'])\n",
    "        train_labels.extend(batch[b'labels'])\n",
    "\n",
    "    test_batch_file = f\"{folder_path}/test_batch\"\n",
    "    test_batch = load_cifar10_batch(test_batch_file)\n",
    "    test_data = test_batch[b'data']\n",
    "    test_labels = test_batch[b'labels']\n",
    "\n",
    "    train_data = np.vstack(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def preprocess_data(train_data, train_labels, test_data, test_labels):\n",
    "    train_data = train_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    test_data = test_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "    train_labels_onehot = to_categorical(train_labels)\n",
    "    test_labels_onehot = to_categorical(test_labels)\n",
    "\n",
    "    return train_data, train_labels_onehot, test_data, test_labels_onehot\n",
    "\n",
    "cifar10_folder = 'cifar-10-batches-py'\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(cifar10_folder)\n",
    "\n",
    "x_train, y_train, x_test, y_test = preprocess_data(\n",
    "    train_data, train_labels, test_data, test_labels\n",
    ")\n",
    "\n",
    "print(\"Train Data Shape:\", x_train.shape)\n",
    "print(\"Train Labels Shape:\", y_train.shape)\n",
    "print(\"Test Data Shape:\", x_test.shape)\n",
    "print(\"Test Labels Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msta314\u001b[0m (\u001b[33mtakim\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'augmentation': {\n",
    "          'values': ['none', 'light', 'heavy']\n",
    "        }\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "parameters_dict.update({\n",
    "    'earlystopping_patience': {\n",
    "        'value': 10},\n",
    "    'epochs': {\n",
    "        'value': 100},\n",
    "    'learning_rate': {\n",
    "        'value': 0.001},\n",
    "    'batch_size': {\n",
    "        'value': 64},\n",
    "    'kernel_size': {\n",
    "          'value': '5x5'},\n",
    "    'net_filter_size': {\n",
    "          'value': 32},\n",
    "    'net_n': {\n",
    "          'value': 3},\n",
    "    'reg_alpha': {\n",
    "          'value': 0.0001},\n",
    "    'normalization': {\n",
    "          'value': False}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'grid',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'augmentation': {'values': ['none', 'light', 'heavy']},\n",
      "                'batch_size': {'value': 64},\n",
      "                'earlystopping_patience': {'value': 10},\n",
      "                'epochs': {'value': 100},\n",
      "                'kernel_size': {'value': '5x5'},\n",
      "                'learning_rate': {'value': 0.001},\n",
      "                'net_filter_size': {'value': 32},\n",
      "                'net_n': {'value': 3},\n",
      "                'normalization': {'value': False},\n",
      "                'reg_alpha': {'value': 0.0001}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: zt6k7al0\n",
      "Sweep URL: https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0\n"
     ]
    }
   ],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project=\"zayif-test\")\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"CIFAR-10_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Lambda, Add, Input, GlobalAveragePooling2D, Flatten, Dense, Softmax\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def ResidualBlock(x, filter_size, is_switch_block, kernel_size, reg_alpha):\n",
    "\n",
    "    # note that if is_switch_block true, it means that output will not be the same as the input\n",
    "    # so while merging the residual connection, we need to adapt to it\n",
    "    # this adaptation could be with a conv layer, or a simple downsampling + padding is enough.\n",
    "\n",
    "    x_skip = x # save original input to the block\n",
    "\n",
    "    if not is_switch_block:\n",
    "        x = Conv2D(filter_size, kernel_size=kernel_size, strides=(1, 1), padding='same', kernel_regularizer=l2(reg_alpha))(x)\n",
    "    else:\n",
    "        x = Conv2D(filter_size, kernel_size=kernel_size, strides=(2, 2), padding='same', kernel_regularizer=l2(reg_alpha))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(filter_size, kernel_size=kernel_size, strides=(1, 1), padding='same', kernel_regularizer=l2(reg_alpha))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    if is_switch_block: # takes every second element to half(v) spatial dimension and then adds padding to each side for matching filter (last) dimension\n",
    "        x_skip = Lambda(lambda x: tf.pad(x[:, ::2, ::2, :], tf.constant([[0, 0,], [0, 0], [0, 0], [filter_size//4, filter_size//4]]), mode=\"CONSTANT\"))(x_skip)\n",
    "\n",
    "    x = Add()([x, x_skip])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def ResidualBlocks(x, filter_size, n, kernel_size, reg_alpha):\n",
    "    for group in range(3): # a stack of 6n layers, 3×3 convolutions, feature maps of sizes {4fs, 2fs, fs}, 2n layers for each size\n",
    "        for block in range(n):\n",
    "            if group > 0 and block == 0: # double filter size\n",
    "                filter_size *= 2\n",
    "                is_switch_block = True\n",
    "            else:\n",
    "                is_switch_block = False\n",
    "                \n",
    "            x = ResidualBlock(x, filter_size, is_switch_block, kernel_size, reg_alpha)\n",
    "\n",
    "    return x\n",
    "\n",
    "def create_model(config):\n",
    "\n",
    "    filter_size = config['net_filter_size']\n",
    "    n = config['net_n']\n",
    "    kernel_size = (3, 3) if config['kernel_size'] == '3x3' else (5, 5)\n",
    "\n",
    "    reg_alpha = config['reg_alpha']\n",
    "\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(filter_size, kernel_size=kernel_size, strides=(1, 1), padding='same', kernel_regularizer=l2(reg_alpha))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = ResidualBlocks(x, filter_size, n, kernel_size, reg_alpha)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10)(x)\n",
    "    outputs = Softmax()(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=f\"ResNet-{n*6+2}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train(config = None):\n",
    "    with wandb.init(config=config):\n",
    "\n",
    "        config = wandb.config\n",
    "\n",
    "        do_normalization = config['normalization']\n",
    "        do_augmentation = config['augmentation'] != 'none'\n",
    "\n",
    "        x_train_to_use = (x_train.astype('float32') / 255) if do_normalization else x_train\n",
    "        x_test_to_use = (x_test.astype('float32') / 255) if do_normalization else x_test\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_model(config)\n",
    "        model.compile(\n",
    "            optimizer = Adam(learning_rate=config[\"learning_rate\"]),\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics = [\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top@3_accuracy')]\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                    patience=config[\"earlystopping_patience\"],\n",
    "                                    restore_best_weights=True)\n",
    "\n",
    "        if not do_augmentation:\n",
    "            history = model.fit(x_train_to_use, y_train,\n",
    "                                epochs=config[\"epochs\"],\n",
    "                                batch_size=config[\"batch_size\"],\n",
    "                                validation_split=0.1,\n",
    "                                callbacks=[\n",
    "                                    WandbMetricsLogger(log_freq='epoch'),\n",
    "                                    early_stopping\n",
    "                                ], verbose=1\n",
    "                                )\n",
    "        else:\n",
    "            if config['augmentation'] == 'light':\n",
    "                datagen = ImageDataGenerator(\n",
    "                    rotation_range=20,\n",
    "                    horizontal_flip=True,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    fill_mode='nearest'\n",
    "                )\n",
    "            else:\n",
    "                datagen = ImageDataGenerator(\n",
    "                    rotation_range=40,\n",
    "                    horizontal_flip=True,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.1,\n",
    "                    fill_mode='nearest'\n",
    "                )\n",
    "\n",
    "            x_tr, x_vl, y_tr, y_vl = train_test_split(x_train_to_use, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "            train_datagen = datagen.flow(x_tr, y_tr, batch_size=config[\"batch_size\"])\n",
    "            history = model.fit(train_datagen,\n",
    "                                epochs=config[\"epochs\"],\n",
    "                                batch_size=config[\"batch_size\"],\n",
    "                                validation_data=(x_vl, y_vl),\n",
    "                                callbacks=[\n",
    "                                    WandbMetricsLogger(log_freq='epoch'),\n",
    "                                    early_stopping\n",
    "                                ], verbose=1\n",
    "                                )\n",
    "            \n",
    "        \n",
    "        test_stats = model.evaluate(x_test_to_use, y_test)\n",
    "        wandb.log({\"test_loss\": test_stats[0]})\n",
    "        wandb.log({\"test_acc\": test_stats[1]})\n",
    "\n",
    "        val_loss_history = history.history['val_loss']\n",
    "        val_acc_history = history.history['val_accuracy']\n",
    "\n",
    "        best_epoch_num = -1 if (len(val_loss_history) == 100 or len(val_loss_history) <= 10) else (len(val_loss_history) - 11)\n",
    "\n",
    "        wandb.log({\"best_val_loss\": val_loss_history[best_epoch_num]})\n",
    "        wandb.log({\"best_val_acc\": val_acc_history[best_epoch_num]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p6hhejtu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: none\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5x5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_filter_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_n: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_alpha: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Stamina\\Desktop\\543Project\\wandb\\run-20240103_030009-p6hhejtu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/p6hhejtu' target=\"_blank\">glamorous-sweep-1</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/p6hhejtu' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/p6hhejtu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - 39s 51ms/step - loss: 1.5230 - accuracy: 0.5016 - top@3_accuracy: 0.8133 - val_loss: 1.3429 - val_accuracy: 0.5672 - val_top@3_accuracy: 0.8686\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 39s 55ms/step - loss: 1.0519 - accuracy: 0.6805 - top@3_accuracy: 0.9132 - val_loss: 1.7686 - val_accuracy: 0.5012 - val_top@3_accuracy: 0.8206\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 42s 60ms/step - loss: 0.8733 - accuracy: 0.7512 - top@3_accuracy: 0.9403 - val_loss: 1.4278 - val_accuracy: 0.6212 - val_top@3_accuracy: 0.8510\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 46s 65ms/step - loss: 0.7908 - accuracy: 0.7846 - top@3_accuracy: 0.9553 - val_loss: 1.3443 - val_accuracy: 0.6006 - val_top@3_accuracy: 0.8884\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 50s 71ms/step - loss: 0.7324 - accuracy: 0.8139 - top@3_accuracy: 0.9644 - val_loss: 0.9462 - val_accuracy: 0.7532 - val_top@3_accuracy: 0.9260\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 52s 74ms/step - loss: 0.6983 - accuracy: 0.8296 - top@3_accuracy: 0.9682 - val_loss: 0.9355 - val_accuracy: 0.7572 - val_top@3_accuracy: 0.9408\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 55s 77ms/step - loss: 0.6664 - accuracy: 0.8450 - top@3_accuracy: 0.9729 - val_loss: 1.0356 - val_accuracy: 0.7260 - val_top@3_accuracy: 0.9376\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 55s 77ms/step - loss: 0.6366 - accuracy: 0.8586 - top@3_accuracy: 0.9767 - val_loss: 1.6047 - val_accuracy: 0.6248 - val_top@3_accuracy: 0.8706\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 55s 79ms/step - loss: 0.6134 - accuracy: 0.8705 - top@3_accuracy: 0.9799 - val_loss: 0.9256 - val_accuracy: 0.7718 - val_top@3_accuracy: 0.9510\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 55s 79ms/step - loss: 0.5799 - accuracy: 0.8837 - top@3_accuracy: 0.9837 - val_loss: 0.9973 - val_accuracy: 0.7520 - val_top@3_accuracy: 0.9476\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 55s 79ms/step - loss: 0.5621 - accuracy: 0.8910 - top@3_accuracy: 0.9862 - val_loss: 1.2388 - val_accuracy: 0.7094 - val_top@3_accuracy: 0.9330\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 56s 79ms/step - loss: 0.5379 - accuracy: 0.9008 - top@3_accuracy: 0.9878 - val_loss: 1.1462 - val_accuracy: 0.7318 - val_top@3_accuracy: 0.9262\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 56s 79ms/step - loss: 0.5367 - accuracy: 0.9059 - top@3_accuracy: 0.9896 - val_loss: 1.0375 - val_accuracy: 0.7620 - val_top@3_accuracy: 0.9336\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 56s 79ms/step - loss: 0.5040 - accuracy: 0.9165 - top@3_accuracy: 0.9904 - val_loss: 1.5926 - val_accuracy: 0.6958 - val_top@3_accuracy: 0.8780\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 56s 79ms/step - loss: 0.4910 - accuracy: 0.9227 - top@3_accuracy: 0.9923 - val_loss: 1.1447 - val_accuracy: 0.7504 - val_top@3_accuracy: 0.9312\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 56s 79ms/step - loss: 0.4789 - accuracy: 0.9287 - top@3_accuracy: 0.9933 - val_loss: 1.0961 - val_accuracy: 0.7614 - val_top@3_accuracy: 0.9542\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.4770 - accuracy: 0.9302 - top@3_accuracy: 0.9940 - val_loss: 1.1767 - val_accuracy: 0.7510 - val_top@3_accuracy: 0.9192\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4576 - accuracy: 0.9382 - top@3_accuracy: 0.9951 - val_loss: 0.8353 - val_accuracy: 0.8254 - val_top@3_accuracy: 0.9638\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4539 - accuracy: 0.9408 - top@3_accuracy: 0.9960 - val_loss: 1.2505 - val_accuracy: 0.7538 - val_top@3_accuracy: 0.9220\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4497 - accuracy: 0.9427 - top@3_accuracy: 0.9958 - val_loss: 1.0787 - val_accuracy: 0.7880 - val_top@3_accuracy: 0.9402\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.4349 - accuracy: 0.9473 - top@3_accuracy: 0.9965 - val_loss: 1.2019 - val_accuracy: 0.7754 - val_top@3_accuracy: 0.9506\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4397 - accuracy: 0.9481 - top@3_accuracy: 0.9968 - val_loss: 0.9387 - val_accuracy: 0.8164 - val_top@3_accuracy: 0.9568\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4216 - accuracy: 0.9529 - top@3_accuracy: 0.9971 - val_loss: 1.1885 - val_accuracy: 0.7732 - val_top@3_accuracy: 0.9456\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4208 - accuracy: 0.9534 - top@3_accuracy: 0.9974 - val_loss: 1.3494 - val_accuracy: 0.7474 - val_top@3_accuracy: 0.9226\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.4364 - accuracy: 0.9509 - top@3_accuracy: 0.9969 - val_loss: 1.1851 - val_accuracy: 0.7880 - val_top@3_accuracy: 0.9528\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4119 - accuracy: 0.9578 - top@3_accuracy: 0.9982 - val_loss: 1.2774 - val_accuracy: 0.7688 - val_top@3_accuracy: 0.9492\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4227 - accuracy: 0.9550 - top@3_accuracy: 0.9976 - val_loss: 1.0094 - val_accuracy: 0.8050 - val_top@3_accuracy: 0.9608\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.4156 - accuracy: 0.9583 - top@3_accuracy: 0.9980 - val_loss: 1.7061 - val_accuracy: 0.6914 - val_top@3_accuracy: 0.9286\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.8517 - accuracy: 0.8170 - top@3_accuracy: 0.9596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae7a15f589d43f38792b5fa848e2257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.030 MB uploaded\\r'), FloatProgress(value=0.038395656248990016, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▅▆▆▇▇▇▇▇▇██████████████████</td></tr><tr><td>epoch/val_accuracy</td><td>▂▁▄▃▆▇▆▄▇▆▅▆▇▅▆▇▆█▆▇▇█▇▆▇▇█▅</td></tr><tr><td>epoch/val_loss</td><td>▅█▅▅▂▂▃▇▂▂▄▃▃▇▃▃▄▁▄▃▄▂▄▅▄▄▂█</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▃▁▂▄▆▇▇▃▇▇▆▆▇▄▆█▆█▆▇▇█▇▆▇▇█▆</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.8254</td></tr><tr><td>best_val_loss</td><td>0.83526</td></tr><tr><td>epoch/accuracy</td><td>0.95831</td></tr><tr><td>epoch/epoch</td><td>27</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.41562</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99804</td></tr><tr><td>epoch/val_accuracy</td><td>0.6914</td></tr><tr><td>epoch/val_loss</td><td>1.70614</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.9286</td></tr><tr><td>test_acc</td><td>0.817</td></tr><tr><td>test_loss</td><td>0.85171</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-sweep-1</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/p6hhejtu' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/p6hhejtu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240103_030009-p6hhejtu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n11y8zac with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: light\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5x5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_filter_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_n: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_alpha: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Stamina\\Desktop\\543Project\\wandb\\run-20240103_032548-n11y8zac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/n11y8zac' target=\"_blank\">polished-sweep-2</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/n11y8zac' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/n11y8zac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - 50s 69ms/step - loss: 1.6803 - accuracy: 0.4422 - top@3_accuracy: 0.7754 - val_loss: 1.7068 - val_accuracy: 0.4326 - val_top@3_accuracy: 0.7656\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 55s 79ms/step - loss: 1.2761 - accuracy: 0.5936 - top@3_accuracy: 0.8727 - val_loss: 1.5201 - val_accuracy: 0.5528 - val_top@3_accuracy: 0.8584\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 1.0889 - accuracy: 0.6696 - top@3_accuracy: 0.9075 - val_loss: 1.3501 - val_accuracy: 0.5988 - val_top@3_accuracy: 0.8982\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.9929 - accuracy: 0.7116 - top@3_accuracy: 0.9258 - val_loss: 0.9923 - val_accuracy: 0.7160 - val_top@3_accuracy: 0.9150\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.9282 - accuracy: 0.7366 - top@3_accuracy: 0.9355 - val_loss: 1.0568 - val_accuracy: 0.7022 - val_top@3_accuracy: 0.9146\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.8878 - accuracy: 0.7568 - top@3_accuracy: 0.9430 - val_loss: 1.0610 - val_accuracy: 0.7028 - val_top@3_accuracy: 0.9292\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.8524 - accuracy: 0.7697 - top@3_accuracy: 0.9466 - val_loss: 1.3823 - val_accuracy: 0.6378 - val_top@3_accuracy: 0.9074\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.8237 - accuracy: 0.7844 - top@3_accuracy: 0.9526 - val_loss: 0.9005 - val_accuracy: 0.7564 - val_top@3_accuracy: 0.9424\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.8053 - accuracy: 0.7940 - top@3_accuracy: 0.9560 - val_loss: 0.8117 - val_accuracy: 0.7946 - val_top@3_accuracy: 0.9508\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 58s 82ms/step - loss: 0.7770 - accuracy: 0.8032 - top@3_accuracy: 0.9600 - val_loss: 0.9375 - val_accuracy: 0.7464 - val_top@3_accuracy: 0.9456\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.7655 - accuracy: 0.8080 - top@3_accuracy: 0.9608 - val_loss: 0.9650 - val_accuracy: 0.7460 - val_top@3_accuracy: 0.9456\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 58s 82ms/step - loss: 0.7446 - accuracy: 0.8182 - top@3_accuracy: 0.9637 - val_loss: 1.1249 - val_accuracy: 0.7296 - val_top@3_accuracy: 0.9136\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.7257 - accuracy: 0.8260 - top@3_accuracy: 0.9654 - val_loss: 0.8607 - val_accuracy: 0.7860 - val_top@3_accuracy: 0.9480\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.7160 - accuracy: 0.8299 - top@3_accuracy: 0.9670 - val_loss: 0.9696 - val_accuracy: 0.7600 - val_top@3_accuracy: 0.9296\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.7029 - accuracy: 0.8342 - top@3_accuracy: 0.9694 - val_loss: 1.5301 - val_accuracy: 0.6638 - val_top@3_accuracy: 0.8504\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.6891 - accuracy: 0.8406 - top@3_accuracy: 0.9707 - val_loss: 0.7559 - val_accuracy: 0.8170 - val_top@3_accuracy: 0.9652\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 58s 83ms/step - loss: 0.6846 - accuracy: 0.8427 - top@3_accuracy: 0.9710 - val_loss: 0.8347 - val_accuracy: 0.8056 - val_top@3_accuracy: 0.9530\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.6774 - accuracy: 0.8453 - top@3_accuracy: 0.9722 - val_loss: 0.8957 - val_accuracy: 0.7822 - val_top@3_accuracy: 0.9492\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.6649 - accuracy: 0.8515 - top@3_accuracy: 0.9719 - val_loss: 0.8782 - val_accuracy: 0.7912 - val_top@3_accuracy: 0.9530\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.6555 - accuracy: 0.8510 - top@3_accuracy: 0.9747 - val_loss: 0.7312 - val_accuracy: 0.8288 - val_top@3_accuracy: 0.9668\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.6466 - accuracy: 0.8563 - top@3_accuracy: 0.9752 - val_loss: 0.9864 - val_accuracy: 0.7638 - val_top@3_accuracy: 0.9504\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.6466 - accuracy: 0.8562 - top@3_accuracy: 0.9760 - val_loss: 0.7785 - val_accuracy: 0.8190 - val_top@3_accuracy: 0.9612\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6394 - accuracy: 0.8590 - top@3_accuracy: 0.9766 - val_loss: 0.8304 - val_accuracy: 0.8034 - val_top@3_accuracy: 0.9532\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.6381 - accuracy: 0.8615 - top@3_accuracy: 0.9765 - val_loss: 0.8164 - val_accuracy: 0.8126 - val_top@3_accuracy: 0.9594\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6253 - accuracy: 0.8646 - top@3_accuracy: 0.9779 - val_loss: 0.8896 - val_accuracy: 0.7956 - val_top@3_accuracy: 0.9438\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6204 - accuracy: 0.8680 - top@3_accuracy: 0.9782 - val_loss: 0.7653 - val_accuracy: 0.8308 - val_top@3_accuracy: 0.9584\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.6151 - accuracy: 0.8675 - top@3_accuracy: 0.9781 - val_loss: 0.8560 - val_accuracy: 0.8006 - val_top@3_accuracy: 0.9514\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6166 - accuracy: 0.8688 - top@3_accuracy: 0.9790 - val_loss: 0.7411 - val_accuracy: 0.8284 - val_top@3_accuracy: 0.9612\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6130 - accuracy: 0.8693 - top@3_accuracy: 0.9790 - val_loss: 0.6747 - val_accuracy: 0.8520 - val_top@3_accuracy: 0.9672\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6026 - accuracy: 0.8734 - top@3_accuracy: 0.9794 - val_loss: 0.7077 - val_accuracy: 0.8462 - val_top@3_accuracy: 0.9704\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6029 - accuracy: 0.8737 - top@3_accuracy: 0.9797 - val_loss: 0.6949 - val_accuracy: 0.8514 - val_top@3_accuracy: 0.9680\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6022 - accuracy: 0.8743 - top@3_accuracy: 0.9804 - val_loss: 0.8509 - val_accuracy: 0.8042 - val_top@3_accuracy: 0.9566\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5955 - accuracy: 0.8766 - top@3_accuracy: 0.9806 - val_loss: 0.7726 - val_accuracy: 0.8220 - val_top@3_accuracy: 0.9642\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5937 - accuracy: 0.8775 - top@3_accuracy: 0.9807 - val_loss: 0.6864 - val_accuracy: 0.8542 - val_top@3_accuracy: 0.9682\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5913 - accuracy: 0.8776 - top@3_accuracy: 0.9810 - val_loss: 0.9508 - val_accuracy: 0.7812 - val_top@3_accuracy: 0.9504\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5837 - accuracy: 0.8800 - top@3_accuracy: 0.9818 - val_loss: 0.8550 - val_accuracy: 0.8118 - val_top@3_accuracy: 0.9466\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5822 - accuracy: 0.8813 - top@3_accuracy: 0.9823 - val_loss: 0.8672 - val_accuracy: 0.8068 - val_top@3_accuracy: 0.9508\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5889 - accuracy: 0.8786 - top@3_accuracy: 0.9824 - val_loss: 1.0387 - val_accuracy: 0.7498 - val_top@3_accuracy: 0.9326\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.5807 - accuracy: 0.8827 - top@3_accuracy: 0.9820 - val_loss: 0.7631 - val_accuracy: 0.8256 - val_top@3_accuracy: 0.9648\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.7039 - accuracy: 0.8452 - top@3_accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a73664054f646b2bbebefc05259e8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▆▅▅▄▆▇▆▆▆▇▆▅▇▇▇▇█▆▇▇▇▇█▇████▇▇█▇▇▇▆█</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▃▄▄▆▃▂▃▃▄▂▃▇▂▂▂▂▁▃▂▂▂▂▂▂▁▁▁▁▂▂▁▃▂▂▃▂</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▄▆▆▆▇▆▇▇▇▇▆▇▇▄█▇▇▇█▇█▇█▇█▇███████▇▇▇▇█</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.852</td></tr><tr><td>best_val_loss</td><td>0.67473</td></tr><tr><td>epoch/accuracy</td><td>0.88267</td></tr><tr><td>epoch/epoch</td><td>38</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.58068</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.98198</td></tr><tr><td>epoch/val_accuracy</td><td>0.8256</td></tr><tr><td>epoch/val_loss</td><td>0.76311</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.9648</td></tr><tr><td>test_acc</td><td>0.8452</td></tr><tr><td>test_loss</td><td>0.70389</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-sweep-2</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/n11y8zac' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/n11y8zac</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240103_032548-n11y8zac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d7n93sxp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: heavy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5x5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_filter_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_n: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \treg_alpha: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Stamina\\Desktop\\543Project\\wandb\\run-20240103_040247-d7n93sxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/d7n93sxp' target=\"_blank\">misty-sweep-3</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/zt6k7al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/d7n93sxp' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/d7n93sxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  5/704 [..............................] - ETA: 39s - loss: 3.3484 - accuracy: 0.1344 - top@3_accuracy: 0.3750WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0301s vs `on_train_batch_end` time: 0.0309s). Check your callbacks.\n",
      "704/704 [==============================] - 58s 79ms/step - loss: 1.7883 - accuracy: 0.3989 - top@3_accuracy: 0.7386 - val_loss: 2.3448 - val_accuracy: 0.3154 - val_top@3_accuracy: 0.6612\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 1.4625 - accuracy: 0.5222 - top@3_accuracy: 0.8320 - val_loss: 1.8753 - val_accuracy: 0.4516 - val_top@3_accuracy: 0.8014\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 1.2919 - accuracy: 0.5923 - top@3_accuracy: 0.8695 - val_loss: 1.6621 - val_accuracy: 0.5316 - val_top@3_accuracy: 0.7992\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 1.1879 - accuracy: 0.6376 - top@3_accuracy: 0.8929 - val_loss: 1.6771 - val_accuracy: 0.5336 - val_top@3_accuracy: 0.8032\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 1.1306 - accuracy: 0.6647 - top@3_accuracy: 0.9063 - val_loss: 1.1752 - val_accuracy: 0.6596 - val_top@3_accuracy: 0.8990\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 1.0809 - accuracy: 0.6885 - top@3_accuracy: 0.9132 - val_loss: 1.3105 - val_accuracy: 0.6626 - val_top@3_accuracy: 0.8588\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 1.0343 - accuracy: 0.7076 - top@3_accuracy: 0.9237 - val_loss: 1.0171 - val_accuracy: 0.7220 - val_top@3_accuracy: 0.9306\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 1.0070 - accuracy: 0.7206 - top@3_accuracy: 0.9281 - val_loss: 1.0878 - val_accuracy: 0.7004 - val_top@3_accuracy: 0.9168\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.9816 - accuracy: 0.7300 - top@3_accuracy: 0.9332 - val_loss: 1.2548 - val_accuracy: 0.6544 - val_top@3_accuracy: 0.8812\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.9521 - accuracy: 0.7461 - top@3_accuracy: 0.9391 - val_loss: 1.0802 - val_accuracy: 0.7204 - val_top@3_accuracy: 0.9188\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.9342 - accuracy: 0.7540 - top@3_accuracy: 0.9422 - val_loss: 1.1357 - val_accuracy: 0.7126 - val_top@3_accuracy: 0.9130\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.9111 - accuracy: 0.7632 - top@3_accuracy: 0.9450 - val_loss: 2.9827 - val_accuracy: 0.4056 - val_top@3_accuracy: 0.8204\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.8960 - accuracy: 0.7691 - top@3_accuracy: 0.9476 - val_loss: 1.0407 - val_accuracy: 0.7324 - val_top@3_accuracy: 0.9246\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8825 - accuracy: 0.7755 - top@3_accuracy: 0.9496 - val_loss: 1.1158 - val_accuracy: 0.7312 - val_top@3_accuracy: 0.9306\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8704 - accuracy: 0.7794 - top@3_accuracy: 0.9524 - val_loss: 1.3665 - val_accuracy: 0.6654 - val_top@3_accuracy: 0.8724\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8546 - accuracy: 0.7861 - top@3_accuracy: 0.9519 - val_loss: 1.0079 - val_accuracy: 0.7564 - val_top@3_accuracy: 0.9544\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8409 - accuracy: 0.7915 - top@3_accuracy: 0.9545 - val_loss: 0.9867 - val_accuracy: 0.7610 - val_top@3_accuracy: 0.9364\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8318 - accuracy: 0.7949 - top@3_accuracy: 0.9563 - val_loss: 1.3038 - val_accuracy: 0.6832 - val_top@3_accuracy: 0.9214\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8166 - accuracy: 0.8018 - top@3_accuracy: 0.9586 - val_loss: 1.1918 - val_accuracy: 0.7182 - val_top@3_accuracy: 0.9130\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8117 - accuracy: 0.8040 - top@3_accuracy: 0.9586 - val_loss: 0.9935 - val_accuracy: 0.7632 - val_top@3_accuracy: 0.9386\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.8023 - accuracy: 0.8051 - top@3_accuracy: 0.9608 - val_loss: 0.8553 - val_accuracy: 0.7924 - val_top@3_accuracy: 0.9630\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7931 - accuracy: 0.8106 - top@3_accuracy: 0.9612 - val_loss: 0.9297 - val_accuracy: 0.7640 - val_top@3_accuracy: 0.9496\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7858 - accuracy: 0.8133 - top@3_accuracy: 0.9621 - val_loss: 1.0800 - val_accuracy: 0.7452 - val_top@3_accuracy: 0.9348\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7789 - accuracy: 0.8174 - top@3_accuracy: 0.9628 - val_loss: 0.8430 - val_accuracy: 0.7992 - val_top@3_accuracy: 0.9470\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7690 - accuracy: 0.8190 - top@3_accuracy: 0.9635 - val_loss: 1.0510 - val_accuracy: 0.7422 - val_top@3_accuracy: 0.9328\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7661 - accuracy: 0.8218 - top@3_accuracy: 0.9649 - val_loss: 0.9958 - val_accuracy: 0.7564 - val_top@3_accuracy: 0.9316\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7652 - accuracy: 0.8200 - top@3_accuracy: 0.9646 - val_loss: 0.9582 - val_accuracy: 0.7734 - val_top@3_accuracy: 0.9412\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7611 - accuracy: 0.8219 - top@3_accuracy: 0.9648 - val_loss: 0.8631 - val_accuracy: 0.8020 - val_top@3_accuracy: 0.9518\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7532 - accuracy: 0.8241 - top@3_accuracy: 0.9658 - val_loss: 0.8354 - val_accuracy: 0.8054 - val_top@3_accuracy: 0.9582\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7477 - accuracy: 0.8280 - top@3_accuracy: 0.9671 - val_loss: 0.9120 - val_accuracy: 0.7742 - val_top@3_accuracy: 0.9542\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7396 - accuracy: 0.8296 - top@3_accuracy: 0.9675 - val_loss: 0.8397 - val_accuracy: 0.8056 - val_top@3_accuracy: 0.9514\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7426 - accuracy: 0.8295 - top@3_accuracy: 0.9679 - val_loss: 0.8702 - val_accuracy: 0.7992 - val_top@3_accuracy: 0.9524\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7375 - accuracy: 0.8302 - top@3_accuracy: 0.9674 - val_loss: 0.9426 - val_accuracy: 0.7758 - val_top@3_accuracy: 0.9448\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7330 - accuracy: 0.8327 - top@3_accuracy: 0.9697 - val_loss: 0.9324 - val_accuracy: 0.7772 - val_top@3_accuracy: 0.9492\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7288 - accuracy: 0.8341 - top@3_accuracy: 0.9686 - val_loss: 1.0901 - val_accuracy: 0.7476 - val_top@3_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7318 - accuracy: 0.8327 - top@3_accuracy: 0.9678 - val_loss: 0.8484 - val_accuracy: 0.8086 - val_top@3_accuracy: 0.9578\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7263 - accuracy: 0.8357 - top@3_accuracy: 0.9691 - val_loss: 0.8408 - val_accuracy: 0.8040 - val_top@3_accuracy: 0.9588\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7256 - accuracy: 0.8388 - top@3_accuracy: 0.9680 - val_loss: 0.7986 - val_accuracy: 0.8202 - val_top@3_accuracy: 0.9636\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7228 - accuracy: 0.8371 - top@3_accuracy: 0.9686 - val_loss: 0.8644 - val_accuracy: 0.8068 - val_top@3_accuracy: 0.9412\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7178 - accuracy: 0.8380 - top@3_accuracy: 0.9706 - val_loss: 0.7105 - val_accuracy: 0.8436 - val_top@3_accuracy: 0.9688\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7150 - accuracy: 0.8420 - top@3_accuracy: 0.9709 - val_loss: 1.0919 - val_accuracy: 0.7472 - val_top@3_accuracy: 0.9326\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7071 - accuracy: 0.8444 - top@3_accuracy: 0.9716 - val_loss: 0.9279 - val_accuracy: 0.7874 - val_top@3_accuracy: 0.9408\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7186 - accuracy: 0.8412 - top@3_accuracy: 0.9696 - val_loss: 0.8240 - val_accuracy: 0.8164 - val_top@3_accuracy: 0.9604\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7076 - accuracy: 0.8442 - top@3_accuracy: 0.9717 - val_loss: 0.8518 - val_accuracy: 0.8036 - val_top@3_accuracy: 0.9642\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.7048 - accuracy: 0.8430 - top@3_accuracy: 0.9711 - val_loss: 1.0538 - val_accuracy: 0.7538 - val_top@3_accuracy: 0.9560\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.7044 - accuracy: 0.8442 - top@3_accuracy: 0.9715 - val_loss: 0.9993 - val_accuracy: 0.7684 - val_top@3_accuracy: 0.9354\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.6943 - accuracy: 0.8476 - top@3_accuracy: 0.9734 - val_loss: 1.0675 - val_accuracy: 0.7386 - val_top@3_accuracy: 0.9416\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6962 - accuracy: 0.8477 - top@3_accuracy: 0.9718 - val_loss: 0.7291 - val_accuracy: 0.8434 - val_top@3_accuracy: 0.9694\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 57s 80ms/step - loss: 0.6958 - accuracy: 0.8471 - top@3_accuracy: 0.9725 - val_loss: 0.8502 - val_accuracy: 0.7996 - val_top@3_accuracy: 0.9560\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.6998 - accuracy: 0.8471 - top@3_accuracy: 0.9727 - val_loss: 0.7427 - val_accuracy: 0.8364 - val_top@3_accuracy: 0.9678\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.7464 - accuracy: 0.8378 - top@3_accuracy: 0.9642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad87b125ab946afbdf6aa597b76af44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▄▆▆▆▅▆▂▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇█▇▇▇██</td></tr><tr><td>epoch/val_loss</td><td>▆▅▄▄▃▂▂▃▂█▂▂▂▂▃▂▁▂▂▁▂▂▁▁▁▁▂▂▁▁▁▁▂▂▁▁▂▂▁▁</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▄▄▄▅▇▇▆▇▅▇▇█▇▇▇██▇▇▇▇████▇████▇▇▇██▇▇██</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.8436</td></tr><tr><td>best_val_loss</td><td>0.71046</td></tr><tr><td>epoch/accuracy</td><td>0.84707</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.69981</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.97271</td></tr><tr><td>epoch/val_accuracy</td><td>0.8364</td></tr><tr><td>epoch/val_loss</td><td>0.74274</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.9678</td></tr><tr><td>test_acc</td><td>0.8378</td></tr><tr><td>test_loss</td><td>0.74642</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-3</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/d7n93sxp' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/d7n93sxp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240103_040247-d7n93sxp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "# wandb.agent(sweep_id, train, count=1)\n",
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
