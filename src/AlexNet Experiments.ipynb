{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and Biases related imports\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (50000, 32, 32, 3)\n",
      "Train Labels Shape: (50000, 10)\n",
      "Test Data Shape: (10000, 32, 32, 3)\n",
      "Test Labels Shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_cifar10_batch(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='bytes')\n",
    "    return batch\n",
    "\n",
    "def load_cifar10_data(folder_path):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        batch_file = f\"{folder_path}/data_batch_{i}\"\n",
    "        batch = load_cifar10_batch(batch_file)\n",
    "        train_data.append(batch[b'data'])\n",
    "        train_labels.extend(batch[b'labels'])\n",
    "\n",
    "    test_batch_file = f\"{folder_path}/test_batch\"\n",
    "    test_batch = load_cifar10_batch(test_batch_file)\n",
    "    test_data = test_batch[b'data']\n",
    "    test_labels = test_batch[b'labels']\n",
    "\n",
    "    train_data = np.vstack(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def preprocess_data(train_data, train_labels, test_data, test_labels):\n",
    "    train_data = train_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    test_data = test_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "    train_labels_onehot = to_categorical(train_labels)\n",
    "    test_labels_onehot = to_categorical(test_labels)\n",
    "\n",
    "    return train_data, train_labels_onehot, test_data, test_labels_onehot\n",
    "\n",
    "cifar10_folder = 'cifar-10-batches-py'\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(cifar10_folder)\n",
    "\n",
    "x_train, y_train, x_test, y_test = preprocess_data(\n",
    "    train_data, train_labels, test_data, test_labels\n",
    ")\n",
    "\n",
    "print(\"Train Data Shape:\", x_train.shape)\n",
    "print(\"Train Labels Shape:\", y_train.shape)\n",
    "print(\"Test Data Shape:\", x_test.shape)\n",
    "print(\"Test Labels Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ['WANDB_NOTEBOOK_NAME'] = 'RUN_1'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'dropout': {\n",
    "          'values': [True, False]\n",
    "        },\n",
    "    'batchnorm': {\n",
    "          'values': [True, False]\n",
    "        },\n",
    "    'regularization': {\n",
    "          'values': [True, False]\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "parameters_dict.update({\n",
    "    'earlystopping_patience': {\n",
    "        'value': 10},\n",
    "    'epochs': {\n",
    "        'value': 100},\n",
    "    'learning_rate': {\n",
    "        'value': 0.000063\n",
    "        },\n",
    "    'batch_size': {\n",
    "          'value': 64\n",
    "        },\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'grid',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'batch_size': {'value': 64},\n",
      "                'batchnorm': {'values': [True, False]},\n",
      "                'dropout': {'values': [True, False]},\n",
      "                'earlystopping_patience': {'value': 10},\n",
      "                'epochs': {'value': 100},\n",
      "                'learning_rate': {'value': 6.3e-05},\n",
      "                'regularization': {'values': [True, False]}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: pavh7fhm\n",
      "Sweep URL: https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"CIFAR-10_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the AlexNet architecture\n",
    "def create_model(dropout, batchnorm, regularization):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    if regularization:\n",
    "        model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(2, 2), activation='relu', input_shape=(32, 32, 3), kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(2, 2), activation='relu', input_shape=(32, 32, 3)))\n",
    "    if batchnorm:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "\n",
    "\n",
    "    if regularization:\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"))\n",
    "    if batchnorm:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "\n",
    "\n",
    "    if regularization:\n",
    "        model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"))\n",
    "    if batchnorm:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
    "    if dropout:\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
    "    if dropout:\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def train(config = None):\n",
    "    with wandb.init(config=config):\n",
    "\n",
    "        config = wandb.config\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_model(config[\"dropout\"], config[\"batchnorm\"], config[\"regularization\"])\n",
    "        model.compile(\n",
    "            optimizer = Adam(learning_rate=config[\"learning_rate\"]),\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics = [\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top@3_accuracy')]\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                    patience=config[\"earlystopping_patience\"],\n",
    "                                    restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                                    epochs=config[\"epochs\"],\n",
    "                                    batch_size=config[\"batch_size\"],\n",
    "                                    validation_split=0.1,\n",
    "                                    callbacks=[\n",
    "                                        WandbMetricsLogger(log_freq='epoch'),\n",
    "                                        early_stopping\n",
    "                                    ], verbose=1\n",
    "                                    )\n",
    "        \n",
    "        test_stats = model.evaluate(x_test, y_test)\n",
    "        wandb.log({\"test_loss\": test_stats[0]})\n",
    "        wandb.log({\"test_acc\": test_stats[1]})\n",
    "\n",
    "        val_loss_history = history.history['val_loss']\n",
    "        val_acc_history = history.history['val_accuracy']\n",
    "\n",
    "        best_epoch_num = -1 if (len(val_loss_history) == 100 or len(val_loss_history) <= 10) else (len(val_loss_history) - 11)\n",
    "\n",
    "        wandb.log({\"best_val_loss\": val_loss_history[best_epoch_num]})\n",
    "        wandb.log({\"best_val_acc\": val_acc_history[best_epoch_num]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5rjnd6zc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: True\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_113812-5rjnd6zc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/5rjnd6zc' target=\"_blank\">electric-sweep-1</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/5rjnd6zc' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/5rjnd6zc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 16s - loss: 5.2502 - accuracy: 0.1055 - top@3_accuracy: 0.3047  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0128s). Check your callbacks.\n",
      "704/704 [==============================] - 20s 24ms/step - loss: 3.1316 - accuracy: 0.3609 - top@3_accuracy: 0.6912 - val_loss: 2.5721 - val_accuracy: 0.4730 - val_top@3_accuracy: 0.8032\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 2.5331 - accuracy: 0.4875 - top@3_accuracy: 0.8034 - val_loss: 2.4125 - val_accuracy: 0.5180 - val_top@3_accuracy: 0.8278\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 2.3299 - accuracy: 0.5413 - top@3_accuracy: 0.8378 - val_loss: 2.4212 - val_accuracy: 0.4900 - val_top@3_accuracy: 0.8060\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 2.1516 - accuracy: 0.5838 - top@3_accuracy: 0.8604 - val_loss: 2.2385 - val_accuracy: 0.5332 - val_top@3_accuracy: 0.8436\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.9946 - accuracy: 0.6194 - top@3_accuracy: 0.8797 - val_loss: 2.0361 - val_accuracy: 0.5942 - val_top@3_accuracy: 0.8732\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.8520 - accuracy: 0.6523 - top@3_accuracy: 0.8957 - val_loss: 2.0395 - val_accuracy: 0.5886 - val_top@3_accuracy: 0.8470\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.7166 - accuracy: 0.6802 - top@3_accuracy: 0.9098 - val_loss: 2.0278 - val_accuracy: 0.5626 - val_top@3_accuracy: 0.8402\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.5859 - accuracy: 0.7067 - top@3_accuracy: 0.9212 - val_loss: 1.8453 - val_accuracy: 0.6006 - val_top@3_accuracy: 0.8652\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.4755 - accuracy: 0.7304 - top@3_accuracy: 0.9320 - val_loss: 1.7091 - val_accuracy: 0.6502 - val_top@3_accuracy: 0.8930\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.3643 - accuracy: 0.7551 - top@3_accuracy: 0.9426 - val_loss: 1.7160 - val_accuracy: 0.6312 - val_top@3_accuracy: 0.8692\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.2652 - accuracy: 0.7804 - top@3_accuracy: 0.9522 - val_loss: 1.6085 - val_accuracy: 0.6562 - val_top@3_accuracy: 0.9058\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.1852 - accuracy: 0.7996 - top@3_accuracy: 0.9600 - val_loss: 1.6062 - val_accuracy: 0.6642 - val_top@3_accuracy: 0.8974\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.1100 - accuracy: 0.8166 - top@3_accuracy: 0.9657 - val_loss: 1.6113 - val_accuracy: 0.6584 - val_top@3_accuracy: 0.8964\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 1.0230 - accuracy: 0.8411 - top@3_accuracy: 0.9732 - val_loss: 1.8099 - val_accuracy: 0.6162 - val_top@3_accuracy: 0.8538\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.9564 - accuracy: 0.8612 - top@3_accuracy: 0.9788 - val_loss: 1.7151 - val_accuracy: 0.6560 - val_top@3_accuracy: 0.8894\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.9129 - accuracy: 0.8714 - top@3_accuracy: 0.9827 - val_loss: 1.7124 - val_accuracy: 0.6370 - val_top@3_accuracy: 0.8910\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.8676 - accuracy: 0.8836 - top@3_accuracy: 0.9850 - val_loss: 1.7988 - val_accuracy: 0.6228 - val_top@3_accuracy: 0.8798\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.8256 - accuracy: 0.8956 - top@3_accuracy: 0.9880 - val_loss: 1.6734 - val_accuracy: 0.6676 - val_top@3_accuracy: 0.9084\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.7832 - accuracy: 0.9064 - top@3_accuracy: 0.9907 - val_loss: 1.7021 - val_accuracy: 0.6642 - val_top@3_accuracy: 0.9008\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.7462 - accuracy: 0.9203 - top@3_accuracy: 0.9924 - val_loss: 1.7315 - val_accuracy: 0.6792 - val_top@3_accuracy: 0.9016\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.7316 - accuracy: 0.9213 - top@3_accuracy: 0.9930 - val_loss: 1.7918 - val_accuracy: 0.6670 - val_top@3_accuracy: 0.8874\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.7026 - accuracy: 0.9293 - top@3_accuracy: 0.9936 - val_loss: 1.6713 - val_accuracy: 0.6910 - val_top@3_accuracy: 0.9084\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.6565 - accuracy: 0.6417 - top@3_accuracy: 0.8895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dab0c857781400ab9b36be86660643f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▄▄▅▅▆▆▆▇▇▇▇▇█████████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▂▃▅▅▄▅▇▆▇▇▇▆▇▆▆▇▇█▇█</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▆▄▄▄▃▂▂▁▁▁▂▂▂▂▁▂▂▂▁</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▃▁▄▆▄▃▅▇▅█▇▇▄▇▇▆█▇█▇█</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6642</td></tr><tr><td>best_val_loss</td><td>1.60621</td></tr><tr><td>epoch/accuracy</td><td>0.92931</td></tr><tr><td>epoch/epoch</td><td>21</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.70258</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99364</td></tr><tr><td>epoch/val_accuracy</td><td>0.691</td></tr><tr><td>epoch/val_loss</td><td>1.67133</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.9084</td></tr><tr><td>test_acc</td><td>0.6417</td></tr><tr><td>test_loss</td><td>1.65651</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-1</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/5rjnd6zc' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/5rjnd6zc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_113812-5rjnd6zc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3z9nwfum with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: False\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_114421-3z9nwfum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/3z9nwfum' target=\"_blank\">likely-sweep-2</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/3z9nwfum' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/3z9nwfum</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 16s - loss: 4.0791 - accuracy: 0.1016 - top@3_accuracy: 0.3281 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0156s). Check your callbacks.\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 2.0264 - accuracy: 0.3512 - top@3_accuracy: 0.6902 - val_loss: 1.6176 - val_accuracy: 0.4402 - val_top@3_accuracy: 0.7692\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 1.4714 - accuracy: 0.4760 - top@3_accuracy: 0.7982 - val_loss: 1.4113 - val_accuracy: 0.5004 - val_top@3_accuracy: 0.8130\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.3101 - accuracy: 0.5374 - top@3_accuracy: 0.8375 - val_loss: 1.2201 - val_accuracy: 0.5672 - val_top@3_accuracy: 0.8564\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 1.1872 - accuracy: 0.5814 - top@3_accuracy: 0.8612 - val_loss: 1.4000 - val_accuracy: 0.4924 - val_top@3_accuracy: 0.8130\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.0880 - accuracy: 0.6190 - top@3_accuracy: 0.8801 - val_loss: 1.2180 - val_accuracy: 0.5754 - val_top@3_accuracy: 0.8544\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.0053 - accuracy: 0.6471 - top@3_accuracy: 0.8939 - val_loss: 1.2105 - val_accuracy: 0.5724 - val_top@3_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.9339 - accuracy: 0.6729 - top@3_accuracy: 0.9068 - val_loss: 1.1598 - val_accuracy: 0.5914 - val_top@3_accuracy: 0.8624\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.8495 - accuracy: 0.7011 - top@3_accuracy: 0.9202 - val_loss: 1.0260 - val_accuracy: 0.6356 - val_top@3_accuracy: 0.8924\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.7812 - accuracy: 0.7268 - top@3_accuracy: 0.9322 - val_loss: 1.1148 - val_accuracy: 0.6108 - val_top@3_accuracy: 0.8740\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.7177 - accuracy: 0.7474 - top@3_accuracy: 0.9414 - val_loss: 1.0662 - val_accuracy: 0.6244 - val_top@3_accuracy: 0.8938\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.6395 - accuracy: 0.7758 - top@3_accuracy: 0.9512 - val_loss: 0.9999 - val_accuracy: 0.6544 - val_top@3_accuracy: 0.9016\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.5804 - accuracy: 0.7975 - top@3_accuracy: 0.9581 - val_loss: 1.0218 - val_accuracy: 0.6540 - val_top@3_accuracy: 0.8984\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.5124 - accuracy: 0.8198 - top@3_accuracy: 0.9670 - val_loss: 1.1189 - val_accuracy: 0.6346 - val_top@3_accuracy: 0.8976\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.4523 - accuracy: 0.8414 - top@3_accuracy: 0.9737 - val_loss: 1.1119 - val_accuracy: 0.6458 - val_top@3_accuracy: 0.8802\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.3924 - accuracy: 0.8639 - top@3_accuracy: 0.9795 - val_loss: 1.0596 - val_accuracy: 0.6550 - val_top@3_accuracy: 0.8976\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.3529 - accuracy: 0.8759 - top@3_accuracy: 0.9840 - val_loss: 1.0635 - val_accuracy: 0.6814 - val_top@3_accuracy: 0.9086\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2992 - accuracy: 0.8954 - top@3_accuracy: 0.9874 - val_loss: 1.0748 - val_accuracy: 0.6890 - val_top@3_accuracy: 0.9168\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2823 - accuracy: 0.9039 - top@3_accuracy: 0.9894 - val_loss: 1.0743 - val_accuracy: 0.6958 - val_top@3_accuracy: 0.9180\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2404 - accuracy: 0.9172 - top@3_accuracy: 0.9924 - val_loss: 1.2353 - val_accuracy: 0.6836 - val_top@3_accuracy: 0.9080\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.2165 - accuracy: 0.9258 - top@3_accuracy: 0.9934 - val_loss: 1.2150 - val_accuracy: 0.6886 - val_top@3_accuracy: 0.9094\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.2018 - accuracy: 0.9304 - top@3_accuracy: 0.9938 - val_loss: 1.3415 - val_accuracy: 0.6700 - val_top@3_accuracy: 0.8996\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0457 - accuracy: 0.6379 - top@3_accuracy: 0.8898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4034d9c3e4745e1a99f72c67c471962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇████████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▂▅▅▅▆▆▆▇▇▆▇▇█████▇</td></tr><tr><td>epoch/val_loss</td><td>█▆▃▆▃▃▃▁▂▂▁▁▂▂▂▂▂▂▄▃▅</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▃▅▃▅▅▅▇▆▇▇▇▇▆▇█████▇</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6544</td></tr><tr><td>best_val_loss</td><td>0.99986</td></tr><tr><td>epoch/accuracy</td><td>0.93044</td></tr><tr><td>epoch/epoch</td><td>20</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.2018</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99382</td></tr><tr><td>epoch/val_accuracy</td><td>0.67</td></tr><tr><td>epoch/val_loss</td><td>1.34154</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8996</td></tr><tr><td>test_acc</td><td>0.6379</td></tr><tr><td>test_loss</td><td>1.04566</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-2</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/3z9nwfum' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/3z9nwfum</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_114421-3z9nwfum\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 155j3ibh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: True\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_115004-155j3ibh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/155j3ibh' target=\"_blank\">youthful-sweep-3</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/155j3ibh' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/155j3ibh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 35s - loss: 5.2325 - accuracy: 0.1484 - top@3_accuracy: 0.3945WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0172s vs `on_train_batch_end` time: 0.0213s). Check your callbacks.\n",
      "704/704 [==============================] - 17s 23ms/step - loss: 2.7058 - accuracy: 0.4430 - top@3_accuracy: 0.7667 - val_loss: 2.4931 - val_accuracy: 0.4964 - val_top@3_accuracy: 0.8190\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 2.2747 - accuracy: 0.5615 - top@3_accuracy: 0.8558 - val_loss: 2.5776 - val_accuracy: 0.4418 - val_top@3_accuracy: 0.7730\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 2.0434 - accuracy: 0.6195 - top@3_accuracy: 0.8831 - val_loss: 2.3145 - val_accuracy: 0.5176 - val_top@3_accuracy: 0.8172\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.8499 - accuracy: 0.6666 - top@3_accuracy: 0.9092 - val_loss: 1.9812 - val_accuracy: 0.6274 - val_top@3_accuracy: 0.8808\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.6788 - accuracy: 0.7051 - top@3_accuracy: 0.9264 - val_loss: 2.1081 - val_accuracy: 0.5820 - val_top@3_accuracy: 0.8568\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.5130 - accuracy: 0.7484 - top@3_accuracy: 0.9435 - val_loss: 2.1223 - val_accuracy: 0.5606 - val_top@3_accuracy: 0.8476\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.3662 - accuracy: 0.7828 - top@3_accuracy: 0.9583 - val_loss: 1.8634 - val_accuracy: 0.6328 - val_top@3_accuracy: 0.8834\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.2228 - accuracy: 0.8226 - top@3_accuracy: 0.9720 - val_loss: 1.9333 - val_accuracy: 0.6252 - val_top@3_accuracy: 0.8882\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.0989 - accuracy: 0.8565 - top@3_accuracy: 0.9818 - val_loss: 1.8685 - val_accuracy: 0.6510 - val_top@3_accuracy: 0.8944\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.9850 - accuracy: 0.8888 - top@3_accuracy: 0.9896 - val_loss: 1.9507 - val_accuracy: 0.6558 - val_top@3_accuracy: 0.8872\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.9070 - accuracy: 0.9087 - top@3_accuracy: 0.9932 - val_loss: 1.8575 - val_accuracy: 0.6726 - val_top@3_accuracy: 0.9010\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.8375 - accuracy: 0.9269 - top@3_accuracy: 0.9956 - val_loss: 2.0353 - val_accuracy: 0.6690 - val_top@3_accuracy: 0.8864\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.7905 - accuracy: 0.9368 - top@3_accuracy: 0.9972 - val_loss: 1.9323 - val_accuracy: 0.6666 - val_top@3_accuracy: 0.8974\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.7636 - accuracy: 0.9423 - top@3_accuracy: 0.9968 - val_loss: 2.0663 - val_accuracy: 0.6734 - val_top@3_accuracy: 0.8960\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.7259 - accuracy: 0.9494 - top@3_accuracy: 0.9982 - val_loss: 2.1322 - val_accuracy: 0.6378 - val_top@3_accuracy: 0.8882\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.6982 - accuracy: 0.9538 - top@3_accuracy: 0.9985 - val_loss: 2.0923 - val_accuracy: 0.6612 - val_top@3_accuracy: 0.8964\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.6608 - accuracy: 0.9616 - top@3_accuracy: 0.9987 - val_loss: 1.8909 - val_accuracy: 0.6850 - val_top@3_accuracy: 0.9068\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.6502 - accuracy: 0.9590 - top@3_accuracy: 0.9984 - val_loss: 2.2279 - val_accuracy: 0.6498 - val_top@3_accuracy: 0.8842\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.6324 - accuracy: 0.9606 - top@3_accuracy: 0.9988 - val_loss: 2.7353 - val_accuracy: 0.6052 - val_top@3_accuracy: 0.8412\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.6079 - accuracy: 0.9640 - top@3_accuracy: 0.9986 - val_loss: 2.2374 - val_accuracy: 0.6542 - val_top@3_accuracy: 0.8940\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.5990 - accuracy: 0.9626 - top@3_accuracy: 0.9989 - val_loss: 2.2028 - val_accuracy: 0.6618 - val_top@3_accuracy: 0.8858\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.9614 - accuracy: 0.6470 - top@3_accuracy: 0.8880\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f90961d59e415ca24a47ca99e5943d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.043 MB uploaded\\r'), FloatProgress(value=0.02507878440619697, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▃▄▅▅▆▆▇▇▇██████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▄▅▅▆▆▇▇▇████████████</td></tr><tr><td>epoch/val_accuracy</td><td>▃▁▃▆▅▄▆▆▇▇██▇█▇▇█▇▆▇▇</td></tr><tr><td>epoch/val_loss</td><td>▆▇▅▂▃▃▁▂▁▂▁▂▂▃▃▃▁▄█▄▄</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▃▁▃▇▅▅▇▇▇▇█▇█▇▇▇█▇▅▇▇</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6726</td></tr><tr><td>best_val_loss</td><td>1.85749</td></tr><tr><td>epoch/accuracy</td><td>0.96262</td></tr><tr><td>epoch/epoch</td><td>20</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.59898</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99889</td></tr><tr><td>epoch/val_accuracy</td><td>0.6618</td></tr><tr><td>epoch/val_loss</td><td>2.2028</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8858</td></tr><tr><td>test_acc</td><td>0.647</td></tr><tr><td>test_loss</td><td>1.96137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-3</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/155j3ibh' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/155j3ibh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_115004-155j3ibh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t8ybr59k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: False\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_115545-t8ybr59k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/t8ybr59k' target=\"_blank\">misty-sweep-4</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/t8ybr59k' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/t8ybr59k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 16s - loss: 3.3905 - accuracy: 0.1562 - top@3_accuracy: 0.3711 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0158s). Check your callbacks.\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 1.5902 - accuracy: 0.4479 - top@3_accuracy: 0.7714 - val_loss: 1.5365 - val_accuracy: 0.4616 - val_top@3_accuracy: 0.7732\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 1.2323 - accuracy: 0.5613 - top@3_accuracy: 0.8542 - val_loss: 1.3778 - val_accuracy: 0.5132 - val_top@3_accuracy: 0.8124\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 1.0744 - accuracy: 0.6184 - top@3_accuracy: 0.8857 - val_loss: 1.4146 - val_accuracy: 0.5042 - val_top@3_accuracy: 0.8104\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.9492 - accuracy: 0.6657 - top@3_accuracy: 0.9073 - val_loss: 1.1413 - val_accuracy: 0.6068 - val_top@3_accuracy: 0.8684\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.8278 - accuracy: 0.7076 - top@3_accuracy: 0.9282 - val_loss: 1.1022 - val_accuracy: 0.6210 - val_top@3_accuracy: 0.8740\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.7128 - accuracy: 0.7477 - top@3_accuracy: 0.9446 - val_loss: 1.2671 - val_accuracy: 0.5768 - val_top@3_accuracy: 0.8416\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.5926 - accuracy: 0.7898 - top@3_accuracy: 0.9606 - val_loss: 1.1357 - val_accuracy: 0.6296 - val_top@3_accuracy: 0.8810\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.4926 - accuracy: 0.8234 - top@3_accuracy: 0.9724 - val_loss: 1.1115 - val_accuracy: 0.6570 - val_top@3_accuracy: 0.8920\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.3735 - accuracy: 0.8669 - top@3_accuracy: 0.9844 - val_loss: 1.1338 - val_accuracy: 0.6632 - val_top@3_accuracy: 0.8914\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2874 - accuracy: 0.8979 - top@3_accuracy: 0.9907 - val_loss: 1.4004 - val_accuracy: 0.6244 - val_top@3_accuracy: 0.8712\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.2490 - accuracy: 0.9129 - top@3_accuracy: 0.9935 - val_loss: 1.5603 - val_accuracy: 0.6252 - val_top@3_accuracy: 0.8522\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1938 - accuracy: 0.9324 - top@3_accuracy: 0.9965 - val_loss: 1.4473 - val_accuracy: 0.6578 - val_top@3_accuracy: 0.8974\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1529 - accuracy: 0.9480 - top@3_accuracy: 0.9977 - val_loss: 1.4616 - val_accuracy: 0.6618 - val_top@3_accuracy: 0.8894\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1447 - accuracy: 0.9499 - top@3_accuracy: 0.9983 - val_loss: 1.4567 - val_accuracy: 0.6708 - val_top@3_accuracy: 0.9020\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1315 - accuracy: 0.9551 - top@3_accuracy: 0.9981 - val_loss: 1.4910 - val_accuracy: 0.6572 - val_top@3_accuracy: 0.8856\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1412 - accuracy: 0.6013 - top@3_accuracy: 0.8731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad67c36516594e71bc60a9acfc93b93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▃▄▅▅▆▆▇▇▇████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▄▄▃▃▂▂▂▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▄▅▅▆▆▇▇███████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▂▆▆▅▇██▆▆████</td></tr><tr><td>epoch/val_loss</td><td>█▅▆▂▁▄▂▁▁▆█▆▆▆▇</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▃▃▆▆▅▇▇▇▆▅█▇█▇</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.621</td></tr><tr><td>best_val_loss</td><td>1.10222</td></tr><tr><td>epoch/accuracy</td><td>0.95511</td></tr><tr><td>epoch/epoch</td><td>14</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.13153</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99807</td></tr><tr><td>epoch/val_accuracy</td><td>0.6572</td></tr><tr><td>epoch/val_loss</td><td>1.49098</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8856</td></tr><tr><td>test_acc</td><td>0.6013</td></tr><tr><td>test_loss</td><td>1.14119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-4</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/t8ybr59k' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/t8ybr59k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_115545-t8ybr59k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rz6zibya with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: True\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_115950-rz6zibya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/rz6zibya' target=\"_blank\">absurd-sweep-5</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/rz6zibya' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/rz6zibya</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 15s - loss: 15.2836 - accuracy: 0.0859 - top@3_accuracy: 0.2930 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_train_batch_end` time: 0.0390s). Check your callbacks.\n",
      "704/704 [==============================] - 16s 21ms/step - loss: 2.9182 - accuracy: 0.3542 - top@3_accuracy: 0.6898 - val_loss: 2.5244 - val_accuracy: 0.4408 - val_top@3_accuracy: 0.7886\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 2.4094 - accuracy: 0.4821 - top@3_accuracy: 0.8035 - val_loss: 2.2721 - val_accuracy: 0.5150 - val_top@3_accuracy: 0.8272\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 2.1796 - accuracy: 0.5390 - top@3_accuracy: 0.8372 - val_loss: 2.2406 - val_accuracy: 0.5136 - val_top@3_accuracy: 0.8110\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 2.0060 - accuracy: 0.5810 - top@3_accuracy: 0.8607 - val_loss: 1.9585 - val_accuracy: 0.6012 - val_top@3_accuracy: 0.8692\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.8362 - accuracy: 0.6232 - top@3_accuracy: 0.8800 - val_loss: 1.9602 - val_accuracy: 0.5884 - val_top@3_accuracy: 0.8684\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.6943 - accuracy: 0.6571 - top@3_accuracy: 0.8980 - val_loss: 1.7762 - val_accuracy: 0.6294 - val_top@3_accuracy: 0.8880\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.5644 - accuracy: 0.6888 - top@3_accuracy: 0.9128 - val_loss: 1.7226 - val_accuracy: 0.6434 - val_top@3_accuracy: 0.8914\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.4507 - accuracy: 0.7161 - top@3_accuracy: 0.9257 - val_loss: 1.6890 - val_accuracy: 0.6456 - val_top@3_accuracy: 0.8968\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.3396 - accuracy: 0.7475 - top@3_accuracy: 0.9390 - val_loss: 1.7262 - val_accuracy: 0.6378 - val_top@3_accuracy: 0.8870\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.2310 - accuracy: 0.7802 - top@3_accuracy: 0.9515 - val_loss: 1.6522 - val_accuracy: 0.6506 - val_top@3_accuracy: 0.8954\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.1404 - accuracy: 0.8047 - top@3_accuracy: 0.9619 - val_loss: 1.7050 - val_accuracy: 0.6556 - val_top@3_accuracy: 0.8946\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.0622 - accuracy: 0.8296 - top@3_accuracy: 0.9692 - val_loss: 1.7514 - val_accuracy: 0.6554 - val_top@3_accuracy: 0.8890\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.9791 - accuracy: 0.8557 - top@3_accuracy: 0.9768 - val_loss: 1.7831 - val_accuracy: 0.6592 - val_top@3_accuracy: 0.8886\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.9320 - accuracy: 0.8701 - top@3_accuracy: 0.9817 - val_loss: 1.8307 - val_accuracy: 0.6572 - val_top@3_accuracy: 0.8940\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8818 - accuracy: 0.8861 - top@3_accuracy: 0.9856 - val_loss: 1.8426 - val_accuracy: 0.6698 - val_top@3_accuracy: 0.8964\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8311 - accuracy: 0.9037 - top@3_accuracy: 0.9889 - val_loss: 2.0792 - val_accuracy: 0.6370 - val_top@3_accuracy: 0.8840\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8026 - accuracy: 0.9130 - top@3_accuracy: 0.9908 - val_loss: 1.9250 - val_accuracy: 0.6576 - val_top@3_accuracy: 0.8924\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7827 - accuracy: 0.9164 - top@3_accuracy: 0.9938 - val_loss: 2.0213 - val_accuracy: 0.6592 - val_top@3_accuracy: 0.8896\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7671 - accuracy: 0.9222 - top@3_accuracy: 0.9938 - val_loss: 2.0242 - val_accuracy: 0.6620 - val_top@3_accuracy: 0.8870\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7327 - accuracy: 0.9338 - top@3_accuracy: 0.9954 - val_loss: 2.1171 - val_accuracy: 0.6538 - val_top@3_accuracy: 0.8816\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.6798 - accuracy: 0.6518 - top@3_accuracy: 0.8870\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05fafe79a434dc6a691c71d0fedb65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.043 MB uploaded\\r'), FloatProgress(value=0.025219201133646268, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▃▄▄▅▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▄▄▅▅▆▆▆▇▇▇▇████████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▃▆▆▇▇▇▇▇█████▇████</td></tr><tr><td>epoch/val_loss</td><td>█▆▆▃▃▂▂▁▂▁▁▂▂▂▃▄▃▄▄▅</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▃▂▆▆▇██▇██▇▇██▇██▇▇</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6506</td></tr><tr><td>best_val_loss</td><td>1.65223</td></tr><tr><td>epoch/accuracy</td><td>0.93376</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.73274</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.9954</td></tr><tr><td>epoch/val_accuracy</td><td>0.6538</td></tr><tr><td>epoch/val_loss</td><td>2.11707</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8816</td></tr><tr><td>test_acc</td><td>0.6518</td></tr><tr><td>test_loss</td><td>1.6798</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-sweep-5</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/rz6zibya' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/rz6zibya</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_115950-rz6zibya\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0rsny63y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: False\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_120456-0rsny63y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/0rsny63y' target=\"_blank\">restful-sweep-6</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/0rsny63y' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/0rsny63y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 14s - loss: 18.4411 - accuracy: 0.1133 - top@3_accuracy: 0.3164 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_train_batch_end` time: 0.0138s). Check your callbacks.\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.9099 - accuracy: 0.3510 - top@3_accuracy: 0.6874 - val_loss: 1.7674 - val_accuracy: 0.3882 - val_top@3_accuracy: 0.7006\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.4648 - accuracy: 0.4696 - top@3_accuracy: 0.7968 - val_loss: 1.3804 - val_accuracy: 0.5134 - val_top@3_accuracy: 0.8244\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.3171 - accuracy: 0.5320 - top@3_accuracy: 0.8326 - val_loss: 1.3026 - val_accuracy: 0.5464 - val_top@3_accuracy: 0.8356\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.2128 - accuracy: 0.5718 - top@3_accuracy: 0.8552 - val_loss: 1.1850 - val_accuracy: 0.5824 - val_top@3_accuracy: 0.8692\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.1086 - accuracy: 0.6095 - top@3_accuracy: 0.8763 - val_loss: 1.1667 - val_accuracy: 0.5902 - val_top@3_accuracy: 0.8694\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.0173 - accuracy: 0.6384 - top@3_accuracy: 0.8947 - val_loss: 1.0950 - val_accuracy: 0.6248 - val_top@3_accuracy: 0.8826\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.9355 - accuracy: 0.6714 - top@3_accuracy: 0.9077 - val_loss: 1.1830 - val_accuracy: 0.5956 - val_top@3_accuracy: 0.8678\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.8464 - accuracy: 0.7023 - top@3_accuracy: 0.9209 - val_loss: 1.1856 - val_accuracy: 0.6124 - val_top@3_accuracy: 0.8644\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.7508 - accuracy: 0.7353 - top@3_accuracy: 0.9360 - val_loss: 1.0549 - val_accuracy: 0.6544 - val_top@3_accuracy: 0.8990\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6697 - accuracy: 0.7639 - top@3_accuracy: 0.9464 - val_loss: 1.1172 - val_accuracy: 0.6478 - val_top@3_accuracy: 0.8836\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.5871 - accuracy: 0.7918 - top@3_accuracy: 0.9583 - val_loss: 1.1388 - val_accuracy: 0.6400 - val_top@3_accuracy: 0.8806\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.5131 - accuracy: 0.8173 - top@3_accuracy: 0.9673 - val_loss: 1.2433 - val_accuracy: 0.6390 - val_top@3_accuracy: 0.8818\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.4336 - accuracy: 0.8475 - top@3_accuracy: 0.9748 - val_loss: 1.2361 - val_accuracy: 0.6372 - val_top@3_accuracy: 0.8882\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.3842 - accuracy: 0.8676 - top@3_accuracy: 0.9806 - val_loss: 1.3979 - val_accuracy: 0.6430 - val_top@3_accuracy: 0.8764\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.3346 - accuracy: 0.8834 - top@3_accuracy: 0.9857 - val_loss: 1.4131 - val_accuracy: 0.6406 - val_top@3_accuracy: 0.8858\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.2912 - accuracy: 0.8989 - top@3_accuracy: 0.9888 - val_loss: 1.4874 - val_accuracy: 0.6520 - val_top@3_accuracy: 0.8888\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.2583 - accuracy: 0.9110 - top@3_accuracy: 0.9911 - val_loss: 1.5249 - val_accuracy: 0.6564 - val_top@3_accuracy: 0.8918\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.2443 - accuracy: 0.9162 - top@3_accuracy: 0.9922 - val_loss: 1.6063 - val_accuracy: 0.6402 - val_top@3_accuracy: 0.8844\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.2124 - accuracy: 0.9270 - top@3_accuracy: 0.9943 - val_loss: 1.6914 - val_accuracy: 0.6478 - val_top@3_accuracy: 0.8826\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0886 - accuracy: 0.6407 - top@3_accuracy: 0.8950\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979aa118ec444ca285a7bdf275f37ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.043 MB uploaded\\r'), FloatProgress(value=0.02531420309198087, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▂▃▄▄▄▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇███████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▅▆▆▇▆▇████▇██████</td></tr><tr><td>epoch/val_loss</td><td>█▄▃▂▂▁▂▂▁▂▂▃▃▄▅▅▆▆▇</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▅▆▇▇▇▇▇█▇▇▇█▇███▇▇</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6544</td></tr><tr><td>best_val_loss</td><td>1.05495</td></tr><tr><td>epoch/accuracy</td><td>0.92702</td></tr><tr><td>epoch/epoch</td><td>18</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.21241</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99429</td></tr><tr><td>epoch/val_accuracy</td><td>0.6478</td></tr><tr><td>epoch/val_loss</td><td>1.69138</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8826</td></tr><tr><td>test_acc</td><td>0.6407</td></tr><tr><td>test_loss</td><td>1.08865</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-6</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/0rsny63y' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/0rsny63y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_120456-0rsny63y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qykj23pd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: True\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_120942-qykj23pd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/qykj23pd' target=\"_blank\">major-sweep-7</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/qykj23pd' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/qykj23pd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 14s - loss: 16.8820 - accuracy: 0.0898 - top@3_accuracy: 0.3125 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_train_batch_end` time: 0.0555s). Check your callbacks.\n",
      "704/704 [==============================] - 16s 21ms/step - loss: 2.8284 - accuracy: 0.4076 - top@3_accuracy: 0.7369 - val_loss: 2.4246 - val_accuracy: 0.4808 - val_top@3_accuracy: 0.8060\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 2.2911 - accuracy: 0.5189 - top@3_accuracy: 0.8255 - val_loss: 2.2075 - val_accuracy: 0.5458 - val_top@3_accuracy: 0.8412\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 2.0793 - accuracy: 0.5699 - top@3_accuracy: 0.8581 - val_loss: 2.1607 - val_accuracy: 0.5492 - val_top@3_accuracy: 0.8298\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.9148 - accuracy: 0.6132 - top@3_accuracy: 0.8798 - val_loss: 1.9519 - val_accuracy: 0.5962 - val_top@3_accuracy: 0.8666\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.7589 - accuracy: 0.6502 - top@3_accuracy: 0.9002 - val_loss: 2.0245 - val_accuracy: 0.5608 - val_top@3_accuracy: 0.8434\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.6270 - accuracy: 0.6850 - top@3_accuracy: 0.9160 - val_loss: 1.8137 - val_accuracy: 0.6226 - val_top@3_accuracy: 0.8750\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.4968 - accuracy: 0.7188 - top@3_accuracy: 0.9314 - val_loss: 1.7478 - val_accuracy: 0.6384 - val_top@3_accuracy: 0.8872\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.3811 - accuracy: 0.7512 - top@3_accuracy: 0.9438 - val_loss: 1.7400 - val_accuracy: 0.6492 - val_top@3_accuracy: 0.8902\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.2704 - accuracy: 0.7808 - top@3_accuracy: 0.9567 - val_loss: 1.7319 - val_accuracy: 0.6622 - val_top@3_accuracy: 0.8910\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.1673 - accuracy: 0.8119 - top@3_accuracy: 0.9659 - val_loss: 1.7491 - val_accuracy: 0.6476 - val_top@3_accuracy: 0.8898\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 1.0721 - accuracy: 0.8409 - top@3_accuracy: 0.9759 - val_loss: 1.8257 - val_accuracy: 0.6628 - val_top@3_accuracy: 0.8964\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.9972 - accuracy: 0.8618 - top@3_accuracy: 0.9815 - val_loss: 1.7981 - val_accuracy: 0.6616 - val_top@3_accuracy: 0.8956\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.9318 - accuracy: 0.8814 - top@3_accuracy: 0.9874 - val_loss: 1.8294 - val_accuracy: 0.6602 - val_top@3_accuracy: 0.8900\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8755 - accuracy: 0.8983 - top@3_accuracy: 0.9905 - val_loss: 1.9865 - val_accuracy: 0.6530 - val_top@3_accuracy: 0.8784\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8340 - accuracy: 0.9115 - top@3_accuracy: 0.9923 - val_loss: 2.0206 - val_accuracy: 0.6632 - val_top@3_accuracy: 0.8940\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8046 - accuracy: 0.9198 - top@3_accuracy: 0.9941 - val_loss: 2.0524 - val_accuracy: 0.6558 - val_top@3_accuracy: 0.8894\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7671 - accuracy: 0.9305 - top@3_accuracy: 0.9954 - val_loss: 2.1595 - val_accuracy: 0.6664 - val_top@3_accuracy: 0.8862\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7479 - accuracy: 0.9350 - top@3_accuracy: 0.9967 - val_loss: 2.1384 - val_accuracy: 0.6562 - val_top@3_accuracy: 0.8830\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7294 - accuracy: 0.9406 - top@3_accuracy: 0.9967 - val_loss: 2.0827 - val_accuracy: 0.6686 - val_top@3_accuracy: 0.8936\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.7443 - accuracy: 0.6537 - top@3_accuracy: 0.8893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e118ddc9b744efe9c0a6d62c5c0ab32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▂▃▄▄▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇████████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▅▄▆▇▇█▇███▇█████</td></tr><tr><td>epoch/val_loss</td><td>█▆▅▃▄▂▁▁▁▁▂▂▂▄▄▄▅▅▅</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▄▃▆▄▆▇██▇███▇█▇▇▇█</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6622</td></tr><tr><td>best_val_loss</td><td>1.73193</td></tr><tr><td>epoch/accuracy</td><td>0.9406</td></tr><tr><td>epoch/epoch</td><td>18</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.7294</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99669</td></tr><tr><td>epoch/val_accuracy</td><td>0.6686</td></tr><tr><td>epoch/val_loss</td><td>2.08268</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8936</td></tr><tr><td>test_acc</td><td>0.6537</td></tr><tr><td>test_loss</td><td>1.74427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sweep-7</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/qykj23pd' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/qykj23pd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_120942-qykj23pd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gi4pzwz4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearlystopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization: False\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Desktop\\NEURAL PROJE\\wandb\\run-20240102_121453-gi4pzwz4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/gi4pzwz4' target=\"_blank\">gentle-sweep-8</a></strong> to <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/takim/CIFAR-10_Classification' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/sweeps/pavh7fhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/gi4pzwz4' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/gi4pzwz4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/704 [..............................] - ETA: 14s - loss: 19.2693 - accuracy: 0.1094 - top@3_accuracy: 0.2578 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.0142s). Check your callbacks.\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 1.8000 - accuracy: 0.4079 - top@3_accuracy: 0.7379 - val_loss: 1.4543 - val_accuracy: 0.4712 - val_top@3_accuracy: 0.8074\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.3464 - accuracy: 0.5200 - top@3_accuracy: 0.8263 - val_loss: 1.3094 - val_accuracy: 0.5346 - val_top@3_accuracy: 0.8332\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.2034 - accuracy: 0.5731 - top@3_accuracy: 0.8578 - val_loss: 1.2319 - val_accuracy: 0.5604 - val_top@3_accuracy: 0.8562\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.1035 - accuracy: 0.6108 - top@3_accuracy: 0.8775 - val_loss: 1.1658 - val_accuracy: 0.5908 - val_top@3_accuracy: 0.8638\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.9915 - accuracy: 0.6493 - top@3_accuracy: 0.8984 - val_loss: 1.1157 - val_accuracy: 0.6116 - val_top@3_accuracy: 0.8696\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.8854 - accuracy: 0.6878 - top@3_accuracy: 0.9165 - val_loss: 1.0794 - val_accuracy: 0.6324 - val_top@3_accuracy: 0.8892\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.7981 - accuracy: 0.7196 - top@3_accuracy: 0.9306 - val_loss: 1.0988 - val_accuracy: 0.6326 - val_top@3_accuracy: 0.8912\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6978 - accuracy: 0.7534 - top@3_accuracy: 0.9458 - val_loss: 1.0962 - val_accuracy: 0.6452 - val_top@3_accuracy: 0.8870\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.6049 - accuracy: 0.7869 - top@3_accuracy: 0.9582 - val_loss: 1.1532 - val_accuracy: 0.6334 - val_top@3_accuracy: 0.8878\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.5158 - accuracy: 0.8186 - top@3_accuracy: 0.9686 - val_loss: 1.3155 - val_accuracy: 0.6180 - val_top@3_accuracy: 0.8792\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.4304 - accuracy: 0.8475 - top@3_accuracy: 0.9777 - val_loss: 1.2303 - val_accuracy: 0.6374 - val_top@3_accuracy: 0.8800\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.3650 - accuracy: 0.8696 - top@3_accuracy: 0.9847 - val_loss: 1.3493 - val_accuracy: 0.6394 - val_top@3_accuracy: 0.8856\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.3100 - accuracy: 0.8913 - top@3_accuracy: 0.9886 - val_loss: 1.3927 - val_accuracy: 0.6406 - val_top@3_accuracy: 0.8818\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.2647 - accuracy: 0.9059 - top@3_accuracy: 0.9918 - val_loss: 1.4502 - val_accuracy: 0.6644 - val_top@3_accuracy: 0.8892\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.2255 - accuracy: 0.9222 - top@3_accuracy: 0.9946 - val_loss: 1.5583 - val_accuracy: 0.6526 - val_top@3_accuracy: 0.8878\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1947 - accuracy: 0.9321 - top@3_accuracy: 0.9956 - val_loss: 1.7333 - val_accuracy: 0.6524 - val_top@3_accuracy: 0.8816\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1198 - accuracy: 0.6183 - top@3_accuracy: 0.8780\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c0221045244178b73d12e5663bee77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.042 MB uploaded\\r'), FloatProgress(value=0.025694820429525356, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▂▃▄▄▅▅▆▆▆▇▇▇███</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▅▄▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>epoch/top@3_accuracy</td><td>▁▃▄▅▅▆▆▇▇▇██████</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▅▆▇▇▇▇▆▇▇▇███</td></tr><tr><td>epoch/val_loss</td><td>▅▃▃▂▁▁▁▁▂▄▃▄▄▅▆█</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>▁▃▅▆▆████▇▇█▇██▇</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.6324</td></tr><tr><td>best_val_loss</td><td>1.07943</td></tr><tr><td>epoch/accuracy</td><td>0.93211</td></tr><tr><td>epoch/epoch</td><td>15</td></tr><tr><td>epoch/learning_rate</td><td>6e-05</td></tr><tr><td>epoch/loss</td><td>0.19469</td></tr><tr><td>epoch/top@3_accuracy</td><td>0.99556</td></tr><tr><td>epoch/val_accuracy</td><td>0.6524</td></tr><tr><td>epoch/val_loss</td><td>1.7333</td></tr><tr><td>epoch/val_top@3_accuracy</td><td>0.8816</td></tr><tr><td>test_acc</td><td>0.6183</td></tr><tr><td>test_loss</td><td>1.11976</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gentle-sweep-8</strong> at: <a href='https://wandb.ai/takim/CIFAR-10_Classification/runs/gi4pzwz4' target=\"_blank\">https://wandb.ai/takim/CIFAR-10_Classification/runs/gi4pzwz4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240102_121453-gi4pzwz4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
